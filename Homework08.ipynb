{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework08\n",
    "\n",
    "Exercises to practice unsupervised learning with clustering\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Get more practice with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the tradeoffs of modeling parameters\n",
    "- Develop intuition for different clustering models and when to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./.devcontainer/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import KMeansClustering, GaussianClustering\n",
    "\n",
    "from image_utils import get_pixels, make_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helmet Sizing\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/PSAM-5020-2025S-A/WK02) and then again in [Homework06](https://github.com/PSAM-5020-2025S-A/Homework06).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load it into a `DataFrame`, like last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "Let's pretend we are designing next-generation helmets with embedded over-the-ear headphones and we want to have a few options for sizes.\n",
    "\n",
    "We could use clustering to see if there is a number of clusters that we can divide our population into, so each size covers a similar portion of the population.\n",
    "\n",
    "We can follow similar steps to regression to create a clustering model that uses features about head and ear sizes:\n",
    "\n",
    "1. Load dataset (done! ðŸŽ‰)\n",
    "2. Encode label features as numbers\n",
    "3. Normalize the data\n",
    "4. Separate the feature variables we want to consider (done below)\n",
    "5. Pick a clustering algorithm\n",
    "6. Determine number of clusters\n",
    "7. Cluster data\n",
    "8. Interpret results\n",
    "\n",
    "For step $5$, it's fine to just pick an algorithm ahead of time to see what happens, but feel free to experiment and plot results for multiple clustering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Encode non-numerical features\n",
    "genders = ['M', 'F']\n",
    "# print(genders)\n",
    "gender_encoder = OrdinalEncoder(categories=[genders])\n",
    "gender_vals = gender_encoder.fit_transform(ansur_df[[\"gender\"]].values)\n",
    "ansur_df[[\"gender\"]] = gender_vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ansur_df[[\"gender\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the data\n",
    "stdScaler = StandardScaler()\n",
    "ansur_scaled_df = stdScaler.fit_transform(ansur_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the features we want to consider\n",
    "ansur_features = ansur_scaled_df[[\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Create Clustering model\n",
    "n_clusters = 7\n",
    "km_model = KMeansClustering(n_clusters=n_clusters, random_state=1010)\n",
    "\n",
    "## Run the model(s) on the data\n",
    "km_predicted = km_model.fit_predict(ansur_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying GaussianClustering model\n",
    "gc_model = GaussianClustering(n_clusters=n_clusters, random_state=1010)\n",
    "\n",
    "## Run the model(s) on the data\n",
    "gc_predicted = gc_model.fit_predict(ansur_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check errors\n",
    "# score\n",
    "print(\"KMeans score:\",km_model.score(ansur_features.values))\n",
    "\n",
    "# distance\n",
    "print(\"KMeans distance score:\", km_model.distance_score())\n",
    "print(\"Gaussian distance score:\", gc_model.distance_score())\n",
    "\n",
    "# balance\n",
    "print(\"KMeans balance score:\", km_model.balance_score()) \n",
    "print(\"Gaussian balance score:\", gc_model.balance_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function copied from https://github.com/PSAM-5020-2025S-A/WK08\n",
    "def plot_clusters(features, labels, clusters, title):\n",
    "  xl, yl, zl = labels[:3]\n",
    "  x = features[xl]\n",
    "  y = features[yl]\n",
    "  z = features[zl]\n",
    "\n",
    "  # 2D\n",
    "  plt.scatter(x, y, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "  plt.title(f\"{title} clustering\")\n",
    "  plt.xlabel(xl)\n",
    "  plt.ylabel(yl)\n",
    "  plt.ylim([-2.2, 3])\n",
    "  plt.show()\n",
    "\n",
    "  plt.scatter(x, z, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "  plt.title(f\"{title} clustering\")\n",
    "  plt.xlabel(xl)\n",
    "  plt.ylabel(zl)\n",
    "  plt.ylim([-2.2, 3])\n",
    "  plt.show()\n",
    "\n",
    "  # 3D\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "  ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "  ax.scatter(x, y, z, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "\n",
    "  ax.set_title(f\"{title} clustering\")\n",
    "  ax.set_xlabel(xl)\n",
    "  ax.set_ylabel(yl)\n",
    "  ax.set_zlabel(zl)\n",
    "  ax.set_ylim(-2.5, 8)\n",
    "  ax.set_zlim(-2.5, 2.5)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot clusters as function of 2 or 3 variables\n",
    "\n",
    "# ansur_features = ansur_scaled_df[[\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]]\n",
    "\n",
    "clusters = km_predicted[\"clusters\"]\n",
    "\n",
    "labels_1 = [\"head.height\", \"head.circumference\", \"ear.length\",]\n",
    "plot_clusters(ansur_features, labels_1, clusters, \"K-Means\")\n",
    "\n",
    "labels_ear = [\"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "plot_clusters(ansur_features, labels_ear, clusters, \"K-Means\")\n",
    "\n",
    "labels_2 = [\"head.circumference\", \"ear.length\", \"ear.breadth\", ]\n",
    "plot_clusters(ansur_features, labels_2, clusters, \"K-Means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Which clustering algorithm did you choose?<br>\n",
    "Did you try a different one?<br>\n",
    "Do the clusters make sense ? Do they look balanced ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "I first tried the KMeans model\n",
    "balance_score returns ~0.93, which is very close to 1, indicating that the clusters are balanced\n",
    "distance_score returns ~1.42, which is a bit greater than 1 standard deviation for the scaled data - this doesn't seem awesome\n",
    "\n",
    "Looking at the graphs for KMeans for various features, there are a few features that seemed to be clustered well, but in some instances the clusters didn't seem very helpful. \n",
    "\n",
    "from the feature combinations I trid out, these graphs shows the most \"clustery\" clusters: head.circumference versus ear.length and head.height versus head.circumference \n",
    "\n",
    "Then I tried the Gaussian model, which seems slightly worse than KMeans -\n",
    "\n",
    "KMeans distance score: 1.4211849284287907\n",
    "Gaussian distance score: 1.458428409698391\n",
    "KMeans balance score: 0.9314583333333333\n",
    "Gaussian balance score: 0.88625\n",
    "\n",
    "The distance is very similar, with KMeans a bit smaller, and the KMeans is also a bit more balanced.\n",
    "\n",
    "Next step would be to try out differe numbers of clusters for each model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out how many cluster\n",
    "\n",
    "Experiment with the number of clusters to see if the initial choice makes sense.\n",
    "\n",
    "The [WK08](https://github.com/PSAM-5020-2025S-A/WK08) notebook had a for loop that can be used to plot errors versus number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Plot errors and pick how many cluster\n",
    "\n",
    "# copied from WK08 notebook - edited to round decimal points to 2 for legibility\n",
    "# try 2 - 10 clusters for K-Means Clustering\n",
    "num_clusters = list(range(2,10))\n",
    "\n",
    "# collect distance, silhouette and balance scores\n",
    "score_scores = []\n",
    "distance_scores = []\n",
    "silhouette_scores = []\n",
    "balance_scores = []\n",
    "\n",
    "# get distance, likelihood and balance for different clustering sizes\n",
    "for n in num_clusters:\n",
    "  mm = KMeansClustering(n_clusters=n)\n",
    "  mm.fit_predict(ansur_features)\n",
    "  score_scores.append(round(mm.score(ansur_features.values), 2))\n",
    "  distance_scores.append(round(mm.distance_score(),2))\n",
    "  silhouette_scores.append(round(mm.silhouette_score(),2))\n",
    "  balance_scores.append(round(mm.balance_score(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"score_scores\", score_scores)\n",
    "print(\"distance_scores\", distance_scores)\n",
    "print(\"silhouette_scores\", silhouette_scores)\n",
    "print(\"balance_scores\", balance_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores as function of number of clusters\n",
    "plt.plot(num_clusters, score_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Distance Squared Sum Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "# plt.ylim([0, 3])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_clusters, distance_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Distance Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "# plt.ylim([0, 3])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_clusters, silhouette_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "# plt.ylim([-1, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_clusters, balance_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Balance Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Based on the graphs of errors versus number of clusters, does it look like we should change the initial number of clusters ?<br>\n",
    "How many clusters should we use ? Why ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "The graphs for each score, apart for balance, which hovers between ~0.9-1 for every cluster size. \n",
    "\n",
    "Since the use case of this might be sizing for helmets, it could be interesting to look at 5 clusters for XS, S, M, L, XL sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revise Number of Clusters.\n",
    "\n",
    "Re-run with the new number of clusters and plot the data in $2D$ or $3D$.\n",
    "\n",
    "This can be the same graph as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Re-run clustering with final number of clusters\n",
    "## Create Clustering model\n",
    "n_clusters_rerun = 5\n",
    "km_model_rerun = KMeansClustering(n_clusters=n_clusters_rerun, random_state=1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the model on the training data\n",
    "km_predicted_rerun = km_model_rerun.fit_predict(ansur_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check errors\n",
    "print(\"KMeans score:\",km_model_rerun.score(ansur_features.values))\n",
    "print(\"KMeans distance score:\", km_model_rerun.distance_score())\n",
    "print(\"KMeans balance score:\", km_model_rerun.balance_score()) \n",
    "print(\"KMeans silhouette score:\", km_model_rerun.silhouette_score()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot in 3D\n",
    "# function copied from https://github.com/PSAM-5020-2025S-A/WK08\n",
    "def plot_clusters_3d(features, labels, clusters, title):\n",
    "  xl, yl, zl = labels[:3]\n",
    "  x = features[xl]\n",
    "  y = features[yl]\n",
    "  z = features[zl]\n",
    "  \n",
    "  # 3D\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "  ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "  ax.scatter(x, y, z, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "\n",
    "  ax.set_title(f\"{title} clustering\")\n",
    "  ax.set_xlabel(xl)\n",
    "  ax.set_ylabel(yl)\n",
    "  ax.set_zlabel(zl)\n",
    "  ax.set_ylim(-2.5, 8)\n",
    "  ax.set_zlim(-2.5, 2.5)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "# ansur_features = ansur_scaled_df[[\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]]\n",
    "clusters_rerun = km_predicted_rerun[\"clusters\"]\n",
    "\n",
    "labels_1_rerun = [\"head.height\", \"head.circumference\", \"ear.length\",]\n",
    "plot_clusters_3d(ansur_features, labels_1_rerun, clusters_rerun, \"K-Means\")\n",
    "\n",
    "labels_ear_rerun = [\"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "plot_clusters_3d(ansur_features, labels_ear_rerun, clusters_rerun, \"K-Means\")\n",
    "\n",
    "labels_2_rerun = [\"head.circumference\", \"ear.length\", \"ear.breadth\", ]\n",
    "plot_clusters_3d(ansur_features, labels_2_rerun, clusters_rerun, \"K-Means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do these look better than the original number of clusters?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "The graph for head.height versus head.circumference looks a bit worse, but the other two graphs I think look a bit beetter. By comparing 5 versus 7 I think I would move forward with 5 due to the clearer size mapping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Organization\n",
    "\n",
    "We have a dataset of about $600$ flower images that we might want to classify by species... eventually.\n",
    "\n",
    "What we want to do first is take a look at all of the images and see what kind of images we have, what kind of colors our flowers have and see if there's any other visual information that could help us classify these images later.\n",
    "\n",
    "We'll see how to use clustering and distances to organize our images by color to create a visualization that we cna use to get to know our dataset.\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "The following cell downloads the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/flowers.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can take a look at a few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"./data/image/flowers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PImage.open(f\"{IMG_DIR}/00_001.png\"))\n",
    "display(PImage.open(f\"{IMG_DIR}/15_001.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Representative Colors\n",
    "\n",
    "The overall process for organizing our images by color will be something like this:\n",
    "\n",
    "1. Iterate over all files in the `data/image/flowers` directory, open each image file and treat it as a dataset\n",
    "   1. Load image into a `DataFrame` where each pixel is a row and R,G,B values are columns/features\n",
    "   2. Cluster into $2$ - $16$ colors\n",
    "   3. Pick $3$ or $4$ representative colors\n",
    "   4. Store image filenames and their representative colors in a Python object\n",
    "2. Once all images have been processed we can order our dataset by different color characteristics: white to black, red to blue, hue value, brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Image\n",
    "\n",
    "Let's step through the process of getting representative colors for one image, and then we can repeat this in a loop to process all of the flower images.\n",
    "\n",
    "#### Open Image\n",
    "\n",
    "The `PIL` library does all the work here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "fname = \"00_001.png\"\n",
    "pimg = PImage.open(f\"{IMG_DIR}/{fname}\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put into `DataFrame`\n",
    "\n",
    "We get the pixels and make a dataset/`DataFrame` out of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into DataFrame\n",
    "pxs = get_pixels(pimg)\n",
    "pxs_df = pd.DataFrame(pxs, columns=[\"R\", \"G\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster colors\n",
    "\n",
    "Create a clustering object, cluster colors into $8$ clusters with `fit_predict()` and take a look at our color palette (`cluster_centers_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Clustering object\n",
    "km_model_flower = KMeansClustering(n_clusters=8)\n",
    "\n",
    "# Cluster by color\n",
    "km_predicted_flower = km_model_flower.fit_predict(pxs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_predicted_flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the color palette (cluster_centers_)\n",
    "km_model_flower.cluster_centers_\n",
    "\n",
    "color_centers = [[round(r), round(g), round(b)] for r,g,b in km_model_flower.cluster_centers_]\n",
    "print(color_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert [0, 255] to [0, 1]\n",
    "c = [(r/255, g/255, b/255) for r,g,b in color_centers]\n",
    "\n",
    "heights = [1] * len(c) # placeholder data\n",
    "fig, ax = plt.subplots(figsize=(8, 1))\n",
    "ax.bar(range(len(c)), heights, color=c, edgecolor='black')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about the colors?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "The majority of the colors are a pink/red hue and green. This makes sense given the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct Image\n",
    "\n",
    "Since we're only doing one image for now, let's take a look at the clustering result.\n",
    "\n",
    "This is like in the lecture notebook. We'll start with an empty pixel array and as we iterate through the `DataFrame` of cluster ids we append the corresponding colors to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# create empty pixel array\n",
    "clustered_pxs = []\n",
    "\n",
    "# iterate through resulting list of cluster ids\n",
    "#  append corresponding color value to pixel array\n",
    "\n",
    "for gidx in km_predicted_flower[\"clusters\"]:\n",
    "  clustered_pxs.append(color_centers[gidx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the image. If this next cell gives errors about using `float` values in images, just make sure the pixel values that are being appended above are all whole number `int` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(clustered_pxs, width=pimg.size[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How does changing the number of clusters affect the resulting image?<br>Try some lower values like <code>2</code> and <code>4</code>, and also some higher ones like <code>12</code> and <code>16</code>. Take a look at a different image.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Clustering object\n",
    "def cluster_flower_colors(n_clusters, fname):\n",
    "  pimg = PImage.open(f\"{IMG_DIR}/{fname}\").convert(\"RGB\")\n",
    "  pxs = get_pixels(pimg)\n",
    "  pxs_df = pd.DataFrame(pxs, columns=[\"R\", \"G\", \"B\"])\n",
    "  km_model_flower = KMeansClustering(n_clusters=n_clusters)\n",
    "  km_predicted_flower = km_model_flower.fit_predict(pxs_df)\n",
    "  color_centers = [[round(r), round(g), round(b)] for r,g,b in km_model_flower.cluster_centers_]\n",
    "  clustered_pxs = []\n",
    "  for gidx in km_predicted_flower[\"clusters\"]:\n",
    "    clustered_pxs.append(color_centers[gidx])\n",
    "  display(make_image(clustered_pxs, width=pimg.size[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flower_colors(2, \"00_001.png\")\n",
    "cluster_flower_colors(10, \"00_001.png\")\n",
    "cluster_flower_colors(16, \"00_001.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flower_colors(2, \"03_021.png\")\n",
    "cluster_flower_colors(10, \"03_021.png\")\n",
    "cluster_flower_colors(16, \"03_021.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flower_colors(2, \"04_026.png\")\n",
    "cluster_flower_colors(10, \"04_026.png\")\n",
    "cluster_flower_colors(16, \"04_026.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "With only 2 clusters the basic outline of each flower is more or less visible, but essentially all detail is lost\n",
    "With 16 clusters the image is pretty good! And the difference between 10 and 16 is not actually so much - enough detail is retained in 10 that it may not be worth using more clusters if feature reduction is the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick Colors\n",
    "\n",
    "Ok, we have some representative colors for our images. We should keep more than one color, but maybe we don't have to keep $12$.\n",
    "\n",
    "We can use the `value_counts()` function of our `DataFrame` to see how many pixels are represented by each of our cluster colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster ids and pixel counts, ordered by descending counts\n",
    "ccounts = km_predicted_flower[\"clusters\"].value_counts()\n",
    "display(ccounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since what we are really trying to do here is get some information about the colors of the flowers present in our images, and given the type of images we have, we can start by assuming that the flower colors will be in the top-$4$ clusters returned by `value_counts()`.\n",
    "\n",
    "We can revisit this assumption later. We might also want to add some filters here to ignore sky and vegetation colors (blues and greens) and only keep flower colors.\n",
    "\n",
    "For now, let's just grab the top-$4$ colors from `value_counts()`, remembering we want to keep their rounded `int` values and not the default `float` values in `cluster_centers_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Object to keep colors for each file\n",
    "file_info = {\n",
    "  \"filename\": fname,\n",
    "  \"colors\": []\n",
    "}\n",
    "\n",
    "# TODO: go through ccounts.index and get corresponding colors for each clusters\n",
    "# TODO: add top-4 colors to the \"colors\" key of the file_color_info object\n",
    "for idx in ccounts.index[:4]:\n",
    "    file_info[\"colors\"].append(km_model_flower.cluster_centers_[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Why might we want to cluster into <code>8</code> or even <code>12</code> colors when in the end we're only keeping <code>4</code>?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "If we only grouped into 4 colors then each color would be less specific, whereas grouping by a higher numbers lets us pick more specific colors and then just keep the top 4 most important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate and Cluster\n",
    "\n",
    "We've processed one image, now let's process $600$... for-loops FTW!\n",
    "\n",
    "We'll need to loop through all of the images in our directory and repeat the process above for each one of them.\n",
    "\n",
    "We can create a function that takes a filename as input and returns the top-$4$ colors for that image, or... we can just put all of the clustering logic in the body of a for loop. Whichever is easiest.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all files in the flowers directory\n",
    "flower_files = sorted([f for f in listdir(IMG_DIR) if f.endswith(\".png\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the loop. In the end we want our `file_colors` list to have objects that have a filename and $4$ colors associated with each filename. Something like:\n",
    "\n",
    "```py\n",
    "[\n",
    "  {\n",
    "    \"filename\": \"00_001.png\",\n",
    "    \"colors\": [[12,44,12], [112,144,62],  [12,84,112], [212,144,102]]\n",
    "  },\n",
    "  {\n",
    "    \"filename\": \"00_002.png\",\n",
    "    \"colors\": [[22,24,28], [112,114,122], [128,200,2], [250,240,230]]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "This can take a while to run (up to a minute for $600$ images). We can use slicing to test our logic on a subset of `flower_files` before processing all $600$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_colors(fname, file_colors):\n",
    "  pimg = PImage.open(f\"{IMG_DIR}/{fname}\").convert(\"RGB\")\n",
    "  pxs = get_pixels(pimg)\n",
    "  pxs_df = pd.DataFrame(pxs, columns=[\"R\", \"G\", \"B\"])\n",
    "  km_predicted_flower = km_model_flower.fit_predict(pxs_df)\n",
    "#   color_centers = [[round(r), round(g), round(b)] for r,g,b in km_model_flower.cluster_centers_]\n",
    "  ccounts = km_predicted_flower[\"clusters\"].value_counts()\n",
    "#   print(ccounts)\n",
    "  for idx in ccounts.index[:4]:\n",
    "    file_colors.append(km_model_flower.cluster_centers_[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cluster_colors(flower_files[0], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# List to keep colors for each file\n",
    "file_colors = []\n",
    "\n",
    "for fname in flower_files:\n",
    "  colors = []\n",
    "  get_cluster_colors(fname, colors)\n",
    "  file_colors.append({  \"filename\": fname,\n",
    "  \"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Images (almost)\n",
    "\n",
    "We have a list with objects that keep track of filenames and representative colors. We could create a `DataFrame` or csv dataset with these, but let's go ahead and just use this directly in this format.\n",
    "\n",
    "What we want to do is re-order our list of objects, but using a `key` function that takes each object's colors into consideration.\n",
    "\n",
    "We'll look into how to do this dynamically later, but for now let's order our images by something like _brightness_. It's _like_ brightness because what we'll do is measure how close each image is to the white color `(255,255,255)`.\n",
    "\n",
    "We'll need some helper functions first:\n",
    "\n",
    "- `color_distance()`: takes $2$ colors and returns the distance between them\n",
    "- `min_color_distance()`: given a reference color and a list of colors, returns the distance between the reference color and the closest color in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def color_distance(c0, c1):\n",
    "  return math.sqrt(sum((a - b) ** 2 for a, b in zip(c0, c1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tests for the `color_distance()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for the color_distance() function\n",
    "print(color_distance([0,0,0], [255,255,255]), \"should be\", 255*3**.5)\n",
    "print(color_distance([0,100,0], [100,100,0]), \"should be\", 100)\n",
    "print(color_distance([55,222,120], [91,51,192]), \"should be\", 189)\n",
    "print(color_distance([147,207,246], [87,57,50]), \"should be\", 254)\n",
    "print(color_distance([12,250,126], [112,10,195]), \"should be\", 269)\n",
    "print(color_distance([106,71,61], [105,136,100]), \"should be\", 75.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns minimum distance between a reference color and colors from a list\n",
    "def min_color_distance(ref_color, color_list):\n",
    "  min = color_distance(color_list[0], ref_color)\n",
    "  for c in color_list:\n",
    "    dist = color_distance(c, ref_color)\n",
    "    if dist < min:\n",
    "      min = dist\n",
    "  return min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three tests for the `min_color_distance()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for the color_distance() function\n",
    "print(min_color_distance([0,0,0], [[255,255,255],[0,100,0],[100,100,0],[58,58,58]]), \"should be\", 100)\n",
    "print(min_color_distance([0,0,0], [[255,255,255],[0,100,0],[100,100,0],[58,57,58]]), \"should be\", 99.88)\n",
    "print(min_color_distance([91,51,192], [[147,207,246],[87,57,50],[12,250,126],[112,10,195]]), \"should be\", 46.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Images (for real now)\n",
    "\n",
    "Alright. We have a function that can be used to order our images by their distance to a given color.\n",
    "\n",
    "Let's order our images by how close they are to the brightest color `(255,255,255)`. We'll define a `key` function that, given an object from our `file_colors` list, returns how close that image is to the color `(255,255,255)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns how close our image is to the color white\n",
    "def by_bright_dist(A):\n",
    "  ref_color=[255,255,255]\n",
    "  min_dist = min_color_distance(ref_color, A[\"colors\"])\n",
    "  return min_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order the list and write out a `JSON` file with the image order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_colors_sorted = sorted(file_colors, key=by_bright_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_sorted = [A[\"filename\"] for A in file_colors_sorted]\n",
    "\n",
    "with open(\"./data/flower_order.json\", \"w\") as ofp:\n",
    "  json.dump(files_sorted, ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Results\n",
    "\n",
    "We can check the results by running a webserver and looking at a simple web page that orders the images according to the resulting `JSON` file from above.\n",
    "\n",
    "We'll make use of the [`Live Server`](https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer) VSCode extension.\n",
    "\n",
    "We can start the server by clicking on the \"_Go Live_\" button towards the right hand side of the bar at the very bottom of our text editor:\n",
    "\n",
    "<img src=\"./imgs/go_live.jpg\" width=\"600px\">\n",
    "\n",
    "Clicking the \"_Go Live_\" button in Codespace should open up a new tab with a plain html navigation view of our repository. Clicking on the `html/` directory should open up a web page with all of the flower images. If not, you can use your Codespace url to try to find the web server address.\n",
    "\n",
    "If your Codespace url is something like:<br>`https://mango-special-giggle-v6v7asd322f7p6.github.dev/`\n",
    "\n",
    "Then, the webserver should be running at:<br>`https://mango-special-giggle-v6v7asd322f7p6-5500.app.github.dev/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review, Contemplate, Experiment\n",
    "\n",
    "Yes, images with white parts are towards the beginning, but the images towards the end aren't necessarily the ones with dark flowers, but are the ones that have all of their representative colors farthest away from white `(255,255,255)`, which includes very saturated colors/images.\n",
    "\n",
    "A couple of interesting experiments here could be:\n",
    "- Decrease the number of clusters or the number of colors kept after clustering.\n",
    "- Use different colors as the reference for the distance functions. For example, create `by_gold_dist()` or `by_purple_dist()` functions to use as the `key` for sorting.\n",
    "- Order the list of cluster colors by [hue](https://stackoverflow.com/questions/23090019/fastest-formula-to-get-hue-from-rgb). This can be a bit tricky to get right because some colors, like white, black and gray, don't have a unique value for hue, but depend on other aspects of the color, like saturation and lightness, to be well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# sort by closest to orange\n",
    "orange = [255, 92, 0]\n",
    "\n",
    "def by_orange_dist(A):\n",
    "  ref_color=orange\n",
    "  min_dist = min_color_distance(ref_color, A[\"colors\"])\n",
    "  return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_colors_orange = sorted(file_colors, key=by_orange_dist)\n",
    "\n",
    "files_orange = [A[\"filename\"] for A in file_colors_orange]\n",
    "\n",
    "with open(\"./data/flower_order.json\", \"w\") as ofp:\n",
    "  json.dump(files_orange, ofp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by closest to pink\n",
    "pink = [255,141,161]\n",
    "\n",
    "def by_pink_dist(A):\n",
    "  ref_color=pink\n",
    "  min_dist = min_color_distance(ref_color, A[\"colors\"])\n",
    "  return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_colors_pink = sorted(file_colors, key=by_pink_dist)\n",
    "\n",
    "files_pink = [A[\"filename\"] for A in file_colors_pink]\n",
    "\n",
    "with open(\"./data/flower_order.json\", \"w\") as ofp:\n",
    "  json.dump(files_pink, ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "What did you try ? What happened ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "by_orange_dist captured all of the orange flowers pretty well (better than the \"brightest\" sorting I think), and there were some pretty good groupings of red, yellow, pink and then white that followed\n",
    "\n",
    "by_pink_dist worked pretty nicely as well, but a bit less well than the orange sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It's challenging to define a set of functions that will perfectly order our flowers by color without first having to define very specific color values for filtering and corner-cases. At a high-level, we can imagine that this is because color is a $3$-dimensional value, and we're using it to organize our images into a single-dimensional order.\n",
    "\n",
    "The beginning of our ordering is usually pretty good, since there's only one way for a color to be _close_ to our reference color, but the ordering gets less consistent towards the end because there are many different ways for a color to be _far_ from the reference color.\n",
    "\n",
    "Next week we'll see a very powerful technique that, amongst other things, will help us get around this kind of \"_dimensionality mismatch_\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
